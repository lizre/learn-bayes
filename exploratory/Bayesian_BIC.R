
# Source
# How to compute Bayes factors using lm, lmer, BayesFactor, brms, and JAGS/stan/pymc3
# https://rpubs.com/lindeloev/bayes_factors
# across these methods, get diff BFs (range 3.7 to 14.1). these "small differences" are likely due to differences in priors. but "brms::hypothesis is erroneous".

# BIC in base R -----
set.seed(14)  # Cherry-picked to reveal the difference between p and BF
intercept_data = data.frame(score=scale(rnorm(40), center=0.72))
View(intercept_data)

# one-sample t test: sig in frequentist terms
x = t.test(intercept_data$score)
x$p.value

# Bayesian approach: whether these data were generated by a world in which intercept=0 or by a world where intercept!=0.
# BF will tell how much the data changes our belief relative to our prior beliefs
# The Bayesian Information Criterion (BIC) is like the more popular AIC but with a slightly different penalization for the number of parameters which allow for a (more) Bayesian interpretation.
# Wagenmakers proposed BIC as alernative to p value: http://www.ejwagenmakers.com/2007/pValueProblems.pdf (A practical solution to the pervasive problems of p values)

lm_1 = lm(score ~ 1, intercept_data)  
BIC(lm_1) 
lm_0 = lm(score ~ 0, intercept_data)  
BIC(lm_0) 
BF_BIC = exp((BIC(lm_0) - BIC(lm_1))/2)  # From BICs to Bayes factor
BF_BIC # 5.05
  # should now believe 5.05 times more in H1 and, conversely, 0.2 times “more” in H0

